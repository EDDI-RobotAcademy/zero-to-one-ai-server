from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from domain.review_summary import ReviewSummary
from application.usecase.preprocess_usecase import PreprocessUseCase
from adapter.output.text_cleaner_adapter import BeautifulSoupTextCleaner
from adapter.output.tokenizer_adapter import KoNLPyTokenizer

router = APIRouter(prefix="/api/reviews", tags=["reviews"])


class PreprocessRequest(BaseModel):
    """ì „ì²˜ë¦¬ ìš”ì²­"""
    reviews: dict[str, str]  # {"1": "ë¦¬ë·° í…ìŠ¤íŠ¸", ...}


class PreprocessResponse(BaseModel):
    """ì „ì²˜ë¦¬ ì‘ë‹µ"""
    id: str
    original: str
    cleaned: str
    tokens: list[str]
    processed: str
    word_count: int


class StatisticsResponse(BaseModel):
    """í†µê³„ ì‘ë‹µ"""
    total_reviews: int
    processed_reviews: int
    avg_word_count: float
    min_word_count: int
    max_word_count: int


@router.post("/preprocess", response_model=list[PreprocessResponse])
async def preprocess_reviews(request: PreprocessRequest):
    """
    ë¦¬ë·° ì „ì²˜ë¦¬ API

    - HTML íƒœê·¸ ì œê±°
    - íŠ¹ìˆ˜ë¬¸ì ì •ì œ
    - í˜•íƒœì†Œ ë¶„ì„
    - ë¶ˆìš©ì–´ ì œê±°
    """
    # ì˜ì¡´ì„± ì£¼ì…
    text_cleaner = BeautifulSoupTextCleaner()
    tokenizer = KoNLPyTokenizer()
    usecase = PreprocessUseCase(text_cleaner, tokenizer)

    # RawReview ê°ì²´ ìƒì„±
    raw_reviews = ReviewSummary.from_json(request.reviews)

    # ì „ì²˜ë¦¬ ì‹¤í–‰
    processed_reviews = usecase.execute(raw_reviews)

    if not processed_reviews:
        raise HTTPException(status_code=400, detail="ìœ íš¨í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤")

    # í†µê³„ ì¶œë ¥ (ë¡œê·¸)
    stats = usecase.get_statistics(processed_reviews)
    print(f"ğŸ“Š ì „ì²˜ë¦¬ í†µê³„: {stats}")

    # Response ë³€í™˜
    return [
        PreprocessResponse(
            id=r.id,
            original=r.original_text,
            cleaned=r.cleaned_text,
            tokens=r.tokens,
            processed=r.processed_text,
            word_count=r.word_count
        )
        for r in processed_reviews
    ]


@router.post("/preprocess/statistics", response_model=StatisticsResponse)
async def get_preprocess_statistics(request: PreprocessRequest):
    """ì „ì²˜ë¦¬ í†µê³„ë§Œ ë°˜í™˜"""
    text_cleaner = BeautifulSoupTextCleaner()
    tokenizer = KoNLPyTokenizer()
    usecase = PreprocessUseCase(text_cleaner, tokenizer)

    raw_reviews = ReviewSummary.from_json(request.reviews)
    processed_reviews = usecase.execute(raw_reviews)

    stats = usecase.get_statistics(processed_reviews)

    return StatisticsResponse(
        total_reviews=len(raw_reviews),
        processed_reviews=len(processed_reviews),
        avg_word_count=stats.get("avg_word_count", 0),
        min_word_count=stats.get("min_word_count", 0),
        max_word_count=stats.get("max_word_count", 0)
    )
